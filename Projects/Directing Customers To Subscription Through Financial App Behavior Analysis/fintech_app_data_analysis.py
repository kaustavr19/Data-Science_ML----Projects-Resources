# -*- coding: utf-8 -*-
"""FinTech App Data Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gaCT9rI1VavUsemVt4XzP9gGmQ7rhjfl
"""

from google.colab import drive
drive.mount('/content/gdrive') #for importing files from g-drive

"""#### Importing essential libraries"""

import numpy as np #for numeric calculations
import pandas as pd #for data analysis and manipulation
import matplotlib.pyplot as plt #for data visualisation
import seaborn as sns #for data visualization
from dateutil import parser #to convert time in date-time dtype

"""#### Import & Explore Dataset"""

finTech_appData = pd.read_csv("/content/gdrive/MyDrive/INDIAN AI PROD/fintech/FineTech_appData.csv")

finTech_appData.shape #get the shape of the data

"""The business dataset contains 50,000 customers information with 12-features."""

finTech_appData.head() #show first 5 rows of the dataset

finTech_appData.tail() #last 5 rows of the dataset

"""The full information about the 'screen_list' column isn't visible. So to visit the full info. we can use the following snippet(for first 5):"""

for i in [1,2,3,4,5]:
  print(finTech_appData.loc[i,'screen_list'],'\n')

"""### About the Dataset

We can see in fineTech_appData DataFrame, there are 50,000 users data with 12 different features.

1. user: Unique ID for each user.

2. first_open: Date (yy-mm-dd) and time (Hour:Minute:Seconds:Milliseconds) of login on app first time.

3. dayofweek: On which day user logon.
  <br>0: Sunday
  <br>1: Monday
  <br>2: Tuesday
  <br>3: Wednesday
  <br>4: Thursday
  <br>5: Friday
  <br>6: Saturday
  
4. Hour: Time of a day in 24-hour format customer logon. It is correlated with dayofweek column.

5. age: The age of the registered user.

6. screen_list: The name of multiple screens seen by customers, which are separated by a comma.

7. numscreens: The total number of screens seen by customers.

8. minigame: Tha app contains small games related to finance. If the customer played mini-game then 1 otherwise 0.

9. used_premium_feature: If the customer used the premium feature of the app then 1 otherwise 0.

10. enrolled: If the user bought a premium feature app then 1 otherwise 0.

11. enrolled_date: On the date (yy-mm-dd) and time (Hour:Minute:Seconds:Milliseconds) the user bought a premium features app.

12. liked: The each screen of the app has a like button if the customer likes it then 1 otherwise 0.
"""

#finding the null value and summation of them
finTech_appData.isnull().sum() #summation of null values

"""We can observe that no other column contains null value except the 'enrolled_date', which has a total of 18926 null values."""

#brief information about the dataset
finTech_appData.info()

"""We can see in the output provided by DataFrame.info() method, there are 50,000 entries (rows) from 0 to 49999 and a total of 12 columns.

All columns have 50,000 non-null values except enrolled_date. It has 31,074 non-null. There is a total of 8 columns that contain integer 64 bit (int64) values and the remaining 4 are object type.

The size of fineTech_appData DataFrame is 4.6 MB.
"""

#ditribution of numeric variables in the dataset
finTech_appData.describe()

"""Observations from the numeric distribution:
1. Mean age of customer is 31.72
2. Only 10.7% of customers played minigame.
3. 17.2% of the customers used the premium features of the app.
4. 16.5% liked it.
5. 62.1% customers enrolled in the premium app.

Now, if we observe the column 'dayofweek' carefully we cannot get proper information.
For this issue, we can print the unique values of each column and their length.
"""

features = finTech_appData.columns
for i in features:
    print("""Unique value of {}\n{}\nlen is {} \n........................\n
          """.format(i, finTech_appData[i].unique(), len(finTech_appData[i].unique())))

"""from the above results we can obtain information from 'dayofweek' and 'hour' column, which tells us that, the customers register in the app each day of the week and 24hrs.

The 'hour' column's data type is object, so we have to convert it to integer format.
"""

finTech_appData['hour'] = finTech_appData.hour.str.slice(1,3).astype(int)

#get data type of each column
finTech_appData.dtypes

"""For the sake of visualization, we need numerical data. So we have to drop the columns with object data type."""

finTech_appData2 = finTech_appData.drop(['user', 'first_open', 'screen_list', 'enrolled_date'], axis = 1)
finTech_appData2.head()

"""# Data Visualization
## Heatmap using correlation matrix
Heatmap is used to find the correlation between each and every features using the correlation matrix.
"""

plt.figure(figsize=(16,9)) #heatmap size ratio 16:9
sns.heatmap(finTech_appData2.corr(), annot=True, cmap='coolwarm')
plt.title("Heatmap using Correlation Matrix of finTech_appData2", fontsize=25)

"""Observations:
1. There is no strong correlation between any feature.
2. There is little correlation between 'numscreens' and 'enrolled', which means that the customers who saw more screen took the premium app.
3. There's also a slight correlation between 'minigame' with 'enrolled' and 'used_premium_features'.
4. There's some negative correlation between 'age' with 'enrolled' and 'numscreens', meaning that older customers don't tend to use the premium app or see multiple scrrens.

## Pair plot of finTech_appData2
It helps to visulaize the distribution of data and scatter plot
"""

sns.pairplot(finTech_appData2, hue = 'enrolled')

